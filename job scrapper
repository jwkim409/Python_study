# requests와 get을 이용하여 웹사이트 구성하는 html 텍스트 받아오기
from requests import get
from bs4 import BeautifulSoup

base_url = "https://weworkremotely.com/remote-jobs/search?term="
search_term = "python"

# 위 변수들을 하나의 url로 만들기
respons = get(f"{base_url}{search_term}")  #f" 필수 기재(덕분에 변수를 넣을 수 있으니)
if respons.status_code != 200:
    print("Can't request website")
else:
    results = []  # for 반복문 밖에 job_list 데려오기 안 그러면 사라지니까(왜 사라짐........????)
    soup = BeautifulSoup(respons.text, 'html.parser') # beautifulsoup에게 html을 보내줌
    jobs = soup.find_all('section', class_="jobs")  # 주의) class_ 언더바 기재
    # print(len(jobs))  # len: 리스트나 튜플의 크기를 줌

    # 모든 li 꺼내오기
    for job_section in jobs:
        for result in results:
            print(result)
            print("///////////////////")
        job_posts = job_section.find_all('li')  # job_posts -> list의 li
        job_posts.pop(-1)  # 맨 끝에 있는 view-all 버튼 지우기  # .은 list임

        """
        # list 안의 코드 실행하기
        for post in job_posts:
            print(post)
            print("/////////////////////////")  # 구분하기 위함
        """

        for post in job_posts: # a태그 안 href 가져오기
            anchor = post.find_all('a')
            anchor = anchor[1]  # 두 번째 링크(href만 필요)
            link = anchor['href'] # BeautifulSoup는 모든 html 태그들을 딕셔너리로 바꿔줌

            # span 안에 class = company(회사명) 가져오기
            company, time, region = anchor.find_all('span', class_='company')
            title = anchor.find('span', class_='title')
            # print(company.string, time.string, region.string, title.string)  # span태그 없이 문자열로 추출하기
            # print("/////////////////////")
            # print("/////////////////////")

            # 문자열 데이터 저장하기
            job_data = {
                'company' : company.string,
                'time' : time.string,
                'region' : region.string,
                'title' : title.string
            }
            results.append(job_data)  # reults야 이 job_data를 너한테 붙여라 (hob_data를 추출할 때마다 list 안에 넣어라)

"""
# Keyword Arguments
class_="jobs" -> class가 jobs인 section들을 모두 찾아
find_all이 많은 변수를 가지고 있기 때문에(name, recursive, string 등등) 언더바를 붙임.
언더바를 붙이는 이유는 class는 이미 파이썬에서 사용하고 있기 때문(if, else를 변수로 설정할 수 없는 것과 같은 의미)


# list에서 각 요소 변수로 만들기
list_of_numbers = [1,2,3]
first, second, third = list_of_numbers

print(first, second, third)
"""
