# 1) requests와 get을 이용하여 웹사이트 구성하는 html 텍스트 받아오기
from requests import get
from bs4 import BeautifulSoup

base_url = "https://weworkremotely.com/remote-jobs/search?term="
search_term = "Python"

# 위 변수들을 하나의 url로 만들기
respons = get(f"{base_url}{search_term}")  #f" 필수 기재(덕분에 변수를 넣을 수 있으니)
if respons.status_code != 200:
    print("Can't request website")
else:
    soup = BeautifulSoup(respons.text, 'html.parser') # beautifulsoup에게 html을 보내줌
    jobs = soup.find_all('section', class_="jobs")  # 주의) class_ 언더바 기재
    # print(len(jobs))  # len: 리스트나 튜플의 크기를 줌

    # 모든 li 꺼내오기
    for job_section in jobs:
        job_posts = job_section.find_all('li')  # job_posts -> list의 li
        job_posts.pop(-1)  # 맨 끝에 있는 view-all 버튼 지우기

    # list 안의 코드 실행하기
        for post in job_posts:
            print(post)
            print("/////////////////////////")  # 구분하기 위함

"""
# Keyword Arguments
class_="jobs" -> class가 jobs인 section들을 모두 찾아
find_all이 많은 변수를 가지고 있기 때문에(name, recursive, string 등등) 언더바를 붙임.
언더바를 붙이는 이유는 class는 이미 파이썬에서 사용하고 있기 때문(if, else를 변수로 설정할 수 없는 것과 같은 의미)
"""
